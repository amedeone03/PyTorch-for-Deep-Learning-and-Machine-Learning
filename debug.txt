import tensorflow as tf

# Path to the saved TensorFlow model
saved_model_dir = "yolov5x_tf_saved_model"

# Initialize the TFLite converter
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)

# Enable optimizations (optional, helps to reduce size and improve performance)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# If you want to quantize to int8 (8-bit), you can set these options:
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # Input type is int8
converter.inference_output_type = tf.int8  # Output type is int8

# Optionally, define a representative dataset generator for further optimization
def representative_data_gen():
    for _ in range(100):
        # Replace this with the shape of the inputs to your YOLOv5 model (e.g., 1, 640, 640, 3)
        yield [tf.random.normal([1, 640, 640, 3], dtype=tf.float32)]

converter.representative_dataset = representative_data_gen

# Convert the model to TFLite format
tflite_model = converter.convert()

# Save the converted TFLite model to a file
with open("yolov5x_quantized.tflite", "wb") as f:
    f.write(tflite_model)

print("TFLite model saved as yolov5x_quantized.tflite")

